{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA & Anomaly Detection Test - Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION:\n",
      "                      Timestamps   Values\n",
      "0     2020-10-17 14:15:00+00:00  160.610\n",
      "1     2020-10-17 14:20:00+00:00  246.250\n",
      "2     2020-10-17 14:25:00+00:00  155.695\n",
      "3     2020-10-17 14:30:00+00:00  171.775\n",
      "4     2020-10-17 14:35:00+00:00  194.660\n",
      "...                         ...      ...\n",
      "17893 2020-12-19 10:07:00+00:00  210.450\n",
      "17894 2020-12-19 10:12:00+00:00  224.440\n",
      "17895 2020-12-19 10:17:00+00:00  222.730\n",
      "17896 2020-12-19 10:22:00+00:00  302.740\n",
      "17897 2020-12-19 10:27:00+00:00  202.990\n",
      "\n",
      "[17898 rows x 2 columns] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import util\n",
    "import json\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "matplotlib.interactive('True')\n",
    "STATE = 42\n",
    "SERVICE = 'ServiceK'\n",
    "LAMBDA = 'LambdaA'\n",
    "METRIC = 'ConcurrentExecutions' # Should be 'Duration' or 'ConcurrentExecutions'\n",
    "METRIC_SLICE = None\n",
    "# METRIC_SLICE = [5000, 8000] # Optional array for using only a slice of the whole metric e.g. [5000, 8000] will use df[5000:8000] later on\n",
    "\n",
    "\n",
    "# Metric conversion from exported CloudWatch JSON to pandas DataFrames\n",
    "metrics = util.json_to_pandas(f'../ExportedMetrics/{SERVICE}/{LAMBDA}.json')\n",
    "for metric in metrics:\n",
    "    print(f'{metric.upper()}:\\n',metrics[metric], '\\n\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing microservice release dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ServiceNames</th>\n",
       "      <th>Timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ServiceA</td>\n",
       "      <td>2020-10-15 13:09:02.003799915+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ServiceHIK</td>\n",
       "      <td>2020-10-15 14:18:49.004899979+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ServiceB</td>\n",
       "      <td>2020-10-15 14:21:56.005199909+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ServiceB</td>\n",
       "      <td>2020-10-19 08:30:09.000400066+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ServiceHIK</td>\n",
       "      <td>2020-10-21 13:49:47.005199909+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ServiceB</td>\n",
       "      <td>2020-10-22 12:20:14.000600100+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ServiceCD</td>\n",
       "      <td>2020-10-23 14:04:43.000400066+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ServiceB</td>\n",
       "      <td>2020-10-28 09:16:09.000900030+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ServiceB</td>\n",
       "      <td>2020-10-28 11:33:24.003599882+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ServiceA</td>\n",
       "      <td>2020-10-29 09:56:09.004199982+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ServiceNames                          Timestamps\n",
       "0     ServiceA 2020-10-15 13:09:02.003799915+00:00\n",
       "1   ServiceHIK 2020-10-15 14:18:49.004899979+00:00\n",
       "2     ServiceB 2020-10-15 14:21:56.005199909+00:00\n",
       "3     ServiceB 2020-10-19 08:30:09.000400066+00:00\n",
       "4   ServiceHIK 2020-10-21 13:49:47.005199909+00:00\n",
       "5     ServiceB 2020-10-22 12:20:14.000600100+00:00\n",
       "6    ServiceCD 2020-10-23 14:04:43.000400066+00:00\n",
       "7     ServiceB 2020-10-28 09:16:09.000900030+00:00\n",
       "8     ServiceB 2020-10-28 11:33:24.003599882+00:00\n",
       "9     ServiceA 2020-10-29 09:56:09.004199982+00:00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "releases = util.load_releases('../ExportedMetrics/releases.json')\n",
    "releases.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some microservices are grouped together during release\n",
    "release_service_map = {\n",
    "    'ServiceA': 'ServiceA',\n",
    "    'ServiceB': 'ServiceB',\n",
    "    'ServiceC': 'ServiceCD',\n",
    "    'ServiceD': 'ServiceCD',\n",
    "    'ServiceE': 'ServiceEF',\n",
    "    'ServiceF': 'ServiceEF',\n",
    "    'ServiceH': 'ServiceHIK',\n",
    "    'ServiceI': 'ServiceHIK',\n",
    "    'ServiceJ': 'ServiceJ',\n",
    "    'ServiceK': 'ServiceHIK'\n",
    "}\n",
    "\n",
    "service_releases = releases.loc[releases['ServiceNames'] == release_service_map[SERVICE]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e5b6516f98bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# df_test = df[5000:8000]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = metrics[METRIC]\n",
    "except:\n",
    "    import winsound\n",
    "    winsound.Beep(700, 200)\n",
    "    winsound.Beep(500, 200)\n",
    "    winsound.Beep(250, 600)\n",
    "        \n",
    "# df_test = df[5000:8000]\n",
    "df_test = df.copy()\n",
    "\n",
    "try:\n",
    "    if (METRIC_SLICE is not None):\n",
    "        df_test = df_test[METRIC_SLICE[0]:METRIC_SLICE[1]]\n",
    "except NameError: # No value for METRIC_SLICE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding feature `PostRelease` for rows right after a microservice deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test.head(1))\n",
    "print(df_test.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = util.calculate_postrelease_feature(df_test, service_releases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test['PostRelease'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_test.Timestamps, df_test.Values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STL Decomposition\n",
    "\n",
    "* Note: The trend around the start and end of the time series is extrapolated, otherwise it would be missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "decompose_result = seasonal_decompose(df_test.Values, period=288, extrapolate_trend='freq')\n",
    "\n",
    "fig, axs = plt.subplots(4,1, figsize=(15,10), sharex=False)\n",
    "axs[0].plot(df_test.Timestamps, df_test.Values)\n",
    "axs[0].set_title('Original values')\n",
    "axs[1].plot(df_test.Timestamps, decompose_result.trend)\n",
    "axs[1].set_title('Trend')\n",
    "axs[2].plot(df_test.Timestamps, decompose_result.seasonal)\n",
    "axs[2].set_title('Seasonal')\n",
    "axs[3].plot(df_test.Timestamps, decompose_result.resid)\n",
    "axs[3].set_title('Residual')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Trend_Values'] = decompose_result.trend\n",
    "df_test['Seasonal_Values'] = decompose_result.seasonal\n",
    "df_test['Residual_Values'] = decompose_result.resid\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting for original values and decomposed residual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IsolationForest(\n",
    "    max_features = 1.0,\n",
    "    n_estimators = 50,\n",
    "    max_samples = 'auto',\n",
    "    contamination = 0.01,\n",
    "    random_state = STATE\n",
    ")\n",
    "model.fit(df_test[['Values']])\n",
    "df_test['Values_Scores'] = model.decision_function(df_test[['Values']])\n",
    "df_test['Values_Inliers'] = model.predict(df_test[['Values']])\n",
    "\n",
    "model.fit(df_test[['Residual_Values']])\n",
    "df_test['Residual_Values_Scores'] = model.decision_function(df_test[['Residual_Values']])\n",
    "df_test['Residual_Values_Inliers'] = model.predict(df_test[['Residual_Values']])\n",
    "\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_anomaly_counts = df_test.Values_Inliers.value_counts()[-1]\n",
    "residual_values_anomaly_counts = df_test.Residual_Values_Inliers.value_counts()[-1]\n",
    "print(f'Anomalous data points from raw values: {values_anomaly_counts} / {len(df_test[\"Values_Inliers\"])}')\n",
    "print(f'Anomalous data points from decomposed residual values: {residual_values_anomaly_counts} / {len(df_test[\"Residual_Values_Inliers\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_anomalies = df_test.loc[df_test.Values_Inliers == -1]\n",
    "residual_values_anomalies = df_test.loc[df_test.Residual_Values_Inliers == -1]\n",
    "release_points = df_test.loc[df_test.PostRelease == 1]\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "plt.figure(figsize=(30,15))\n",
    "plt.plot(df_test.Timestamps, df_test.Values)\n",
    "plt.plot(values_anomalies.Timestamps, values_anomalies.Values, 'o', color='green')\n",
    "plt.plot(residual_values_anomalies.Timestamps, residual_values_anomalies.Values, 'x', color='orange')\n",
    "\n",
    "for release in release_points.Timestamps:\n",
    "    plt.axvline(release, color='purple')\n",
    "\n",
    "plt.title(f'Isolation forest anomaly detection - {SERVICE}, {LAMBDA} - {METRIC}')\n",
    "plt.legend(['Values', 'Anomalies from raw values', 'Anomalies from decomposed residual values', 'Release dates'])\n",
    "\n",
    "\n",
    "# Output .png & .eps files\n",
    "import os\n",
    "\n",
    "savedir = f'{os.getcwd()}\\\\output\\\\{SERVICE}\\\\{LAMBDA}'\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "plt.savefig(f'{savedir}\\\\{METRIC}.eps')\n",
    "plt.savefig(f'{savedir}\\\\{METRIC}.png')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import winsound\n",
    "winsound.Beep(200, 100)\n",
    "winsound.Beep(300*2, 100)\n",
    "winsound.Beep(300*2, 100)\n",
    "winsound.Beep(300*2, 100)\n",
    "winsound.Beep(300*2, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
